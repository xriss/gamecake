<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
    Documentation for Lua Lanes
-->

<html>
<head>
  <meta name="description" content="Lua Lanes - multithreading in Lua" />
  <meta name="keywords" content="Lua, Library, Multithreading, Threads, Rocks" />

  <title>Lua Lanes - multithreading in Lua</title>
</head>

<body>
<div class="header">
<hr />

<center>
<table summary="Lua logo">
  <tbody>
    <tr>
      <td align="center">
      <a href="http://www.lua.org">
        <img src="multi.png" alt="Lua" align="middle" border="0" height="120" width="128" />
        <img src="multi.png" alt="Lua" align="middle" border="0" height="120" width="128" />
        <img src="multi.png" alt="Lua" align="middle" border="0" height="120" width="128" />
        <img src="multi.png" alt="Lua" align="middle" border="0" height="120" width="128" />
        <img src="multi.png" alt="Lua" align="middle" border="0" height="120" width="128" />
      </a></td>
    </tr>
    <tr>
      <td align="center" valign="top"><h1>Lua Lanes - multithreading in Lua</h1>
      </td>
    </tr>
  </tbody>
</table>

<p class="bar">
  <a href="#description">Description</a> &middot;
  <a href="#systems">Supported systems</a> &middot;
  <a href="#installing">Installing</a>
</p><p class="bar">
  <a href="#creation">Creation</a> &middot;
  <a href="#status">Status</a> &middot;
  <a href="#results">Results and errors</a> &middot;
  <a href="#cancelling">Cancelling</a>
</p><p class="bar">
<!--  <a href="#misc">Misc</a> &middot; -->
  <a href="#lindas">Lindas</a> &middot;
  <a href="#timers">Timers</a> &middot;
  <a href="#locks">Locks</a>
</p><p class="bar">
  <a href="#other">Other issues</a> &middot;
  <a href="#changes">Change log</a>
  <!-- ... -->

<p><br/><font size="-1"><i>Copyright &copy; 2007-08 Asko Kauppi. All rights reserved.</i>
    <br>Lua Lanes is published under the same <A HREF="http://en.wikipedia.org/wiki/MIT_License">MIT license</A> as Lua 5.1.
    </p><p>This document was revised on 25-Jul-08, and applies to version 2008.
</font></p>

</center>
</div>


<!-- description +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="description">Description</h2>

<p>Lua Lanes is a Lua extension library providing
    the possibility to run multiple Lua states in parallel. It is intended to
    be used for optimizing performance on multicore CPU's and to study ways to make Lua programs naturally parallel to begin with.
</p><p>
    Lanes is included into your software by the regular
    <tt>require "lanes"</tt> method. No C side programming is needed; all APIs are Lua side, and most existing extension modules should
    work seamlessly together with the multiple lanes.<sup><a href="#1">1</a></sup>
</p><p>
    See <A HREF="comparison.html">comparison</A> of Lua Lanes with other Lua multithreading solutions.
</p><p>
    <h3>Features:</h3>

  <ul>
    <li>States have separated data, by default
    </li>
    <li>Communications is separate of threads, using Linda objects for message passing and shared tables
    </li>
    <li>No serialization required; data passing uses fast inter-state copies (via hidden interim state)</li>
    </li>
    <li>All pending calls can be timeouted (naturally).
    </li>
    <li>Millisecond level timers, integrated with the Linda system.
    </li>
    <li>Threads can be given priorities -2..+2 (default is 0).
    </li>
    <li>Lanes are cancellable
    </li>
    <li>No application level locking - ever!
    </li>
  </ul>


<h3>Limitations:</h3>

  <ul><li>coroutines, cyclic tables and metatables are not passed between states</li>

      <li>sharing full userdata between states needs special C side
          preparations (-&gt; <A HREF="#deep_userdata">deep userdata</A>)
      </li>
  </ul>
</p>


<!-- systems +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="systems">Supported systems</h2>

<p>Lua Lanes supports the following operating systems:

    <ul>
        <li>Mac OS X PowerPC / Intel</li>
        <li>Linux x86</li>
        <li>Windows XP <font size="-1">(MinGW or Visual C++ 2005/2008)</font></li>
    </ul>
    
    <p>The underlying threading code can be compiled either towards Win32 API 
    or <a TARGET="_blank" HREF="http://en.wikipedia.org/wiki/POSIX_Threads">Pthreads</a>. Unfortunately, thread prioritation under Pthreads is a JOKE, 
    requiring OS specific tweaks and guessing undocumented behaviour. Other
    features should be portable to any modern platform.
    </p>
    <p>If you wish more platform support, please <A HREF="mailto:akauppi@gmail.com">sign up</A> as a test resource 
    (BSD, Linux x64, QNX, Solaris, Win64, ...).
    </p>
</p>


<!-- installing +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="installing">Installing</h2>

<p>Lua Lanes is intended to be installed via <A HREF="http://www.luarocks.org" TARGET="_blank">Lua Rocks</A> package management.

<pre>
  > luarocks search lanes
    ... output listing Lua Lanes is there ...

  > luarocks install lanes
    ... output ...
</pre>

<p>To compile from source, run <tt>make</tt> and <tt>make test</tt> (also on Windows).
</p>


<!-- launching +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="creation">Creation</h2>

<p>The following sample shows preparing a function for parallel calling, and
calling it with varying arguments. Each of the two results is calculated in
a separate OS thread, parallel to the calling one. Reading the results
automatically joins the threads, waiting for any results not already there.
</p>

<table border=1 bgcolor="#FFFFE0" width=500><tr><td>
<pre>
  require "lanes"

  f= lanes.gen( function(n) return 2*n end )
  a= f(1)
  b= f(2)

  print( a[1], b[1] )     -- 2    4
</pre>
</table>

<p>
<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>func= lanes.gen( [libs_str | opt_tbl [, ...],] lane_func )
    <br/><br/>
    lane_h= func( ... )</code>
</table>
</p>
</p><p>
    The function returned by <tt>lanes.gen()</tt> is a "generator" for
    launching any number of lanes. They will share code, options, initial globals,
    but the particular arguments may vary. Only calling the generator function
    actually launches a lane, and provides a handle for controlling it.
<!--
</p>
<p>This prepares <tt>lane_func</tt> to be called in parallel. It does not yet start
anything, but merely returns a <i>generator function</i> that can be called
any number of times, with varying parameters. Each call will spawn a new lane.
-->
</p><p>
Note that Lanes automatically copies upvalues over to the new lanes, so you
need not wrap all the required functions into one 'wrapper' function. If
<tt>lane_func</tt> uses some local values, or functions, they will be there
also in the new lanes.
</p><p>
    <code>libs_str</code> defines the standard libraries made available to the
    new Lua state:
    <table>
        <tr><td/><td>(nothing)</td><td>no standard libraries</td></tr>
        <tr><td width=40><td><tt>"base"</tt> or <tt>""</tt></td>
            <td>root level names, <tt>print</tt>, <tt>assert</tt>, <tt>unpack</tt> etc.</td></tr>
        <tr><td/><td><tt>"coroutine"</tt></td><td><tt>coroutine.*</tt> namespace (part of base in Lua 5.1)</td></tr>
        <tr><td/><td><tt>"debug"</tt></td><td><tt>debug.*</tt> namespace</td></tr>
        <tr><td/><td><tt>"io"</tt></td><td><tt>io.*</tt> namespace</td></tr>
        <tr><td/><td><tt>"math"</tt></td><td><tt>math.*</tt> namespace</td></tr>
        <tr><td/><td><tt>"os"</tt></td><td><tt>os.*</tt> namespace</td></tr>
        <tr><td/><td><tt>"package"</tt></td><td><tt>package.*</tt> namespace and <tt>require</tt></td></tr>
        <tr><td/><td><tt>"string"</tt></td><td><tt>string.*</tt> namespace</td></tr>
        <tr><td/><td><tt>"table"</tt></td><td><tt>table.*</tt> namespace</td></tr>
        <br/>
        <tr><td/><td><tt>"*"</tt></td><td>all standard libraries, and <tt>send</tt></td></tr>
    </table>

</p><p>
    Initializing the standard libs takes a bit of time at each lane invocation.
    This is the main reason why "no libraries" is the default.
</p><p>
    <i>Note: In Lua 5.1, <tt>'coroutine'</tt> namespace is part of the base library.
    This may not be the case in later versions, so explicit use of "coroutine"
    is recommended, if the lane intends to use them.</i>
</p><p>

    <code>opt_tbl</code> is a collection of named options to control the way
    lanes are run:
</p><p>
  <table>
    <tr valign=top><td/><td>
        <code>.cancelstep</code> <br/><nobr>N / true</nobr></td>
    <td>
    By default, lanes are only cancellable when they do a pending
    <tt>:receive()</tt> or <tt>:send()</tt> call.
    With this option, one can set cancellation check to occur every <tt>N</tt>
    Lua statements. The value <tt>true</tt> uses a default value (100).
    </td></tr>

    <tr valign=top><td/><td>
        <code>.globals</code> <br/>globals_tbl</td>
    <td>
    Sets the globals table for the launched threads. This can be used for giving
    them constants.
    </p><p>
    <i>NOTE: The global values of different lanes are in no manner connected;
    modifying one will only affect the particular lane.</i>
    </td></tr>

    <tr valign=top><td width=40><td>
        <code>.priority</code> <br/><nobr>-2..+2</nobr></td>
        <td>The priority of lane(s). -2 is lowest, +2 is highest.
        <p>
    Note that implementation and dependability of priorities varies
    by platform. Especially Linux kernel 2.6 is not supporting priorities in user mode.
    </td></tr>

<!--
    <tr valign=top><td/><td>
        <code>.lazy</code> <br/>true</td>
    <td>
    Sets the eagerness of evaluation. Eager lanes (default) begin executing
    right ahead, and may get their results evaluated before they are actually
    required (good use of multithreading).
    Lazy lanes won't be using up CPU power until once their values are truly
    required (if ever). This may be useful i.e. for Makefile-like flow processing,
    where all the relationships are described up front, but maybe only some of
    the end results are actually required to be built. An eager solution would
    start all builds, in parallel, always.
    </td></tr>
-->
  </table>
</p>


<!-- status +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="status">Status</h2>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>str= lane_h.status</code>
</table>

<p>The current execution state of a lane can be read via its <tt>status</tt>
member, providing one of these values: <sup>(<a href="#2">2</a></sup>

    <table>
        <tr><td width=40><td><tt>"pending"</tt></td><td>not started, yet</td></tr>
        <tr><td/><td><tt>"running"</tt></td><td>running</td></tr>
        <tr><td/><td><tt>"waiting"</tt></td><td>waiting at a Linda <tt>:receive()</tt> or <tt>:send()</tt></td></tr>
        <tr><td/><td><tt>"done"</tt></td><td>finished executing (results are ready)</td></tr>
        <tr><td/><td><tt>"error"</tt></td><td>met an error (reading results will propagate it)</td></tr>
        <tr><td/><td><tt>"cancelled"</tt></td><td>received cancellation and finished itself</td></tr>
    </table>
</p>


<!-- results +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="results">Results and errors</h2>

<p>A lane can be waited upon by simply reading its results.
</p><p>
The lane's results are available as an array of <tt>[1..N]</tt> indices. 
Reading any of them will make sure the thread has been completed. 
<tt>lane_h:join()</tt> can be used to get all the results at once, and/or
if a timeout is required.
</p><p>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>[val]= lane_h[1]</code>
</table>
<p>
Makes sure lane has finished, and gives its first (maybe only) return value.
Other return values will be available in other <tt>lane_h</tt> indices.
</p>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>[...]|[nil,err]= lane_h:join( [timeout_secs] [, error_propagate=true] )</code>
</table>
<p>
Returns <tt>nil</tt> if the lane hasn't finished before timeout. Otherwise
waits until the lane finishes, and returns the values.
If you use timeouts, make sure your lane main function returns
a value so you can tell timeout-return and done-return apart (or use the
<tt>.state</tt> property).
</p>

<p>If your lane code hits an error, it does not instantly affect other running
lanes, neither report the error anywhere. Only once the lane's results are
acquired, the error is propagated to the reading lane.
</p>
<p>By giving <tt>false</tt> as the <tt>error_propagate</tt> parameter, you
will get the Lua-ish <tt>nil, error_value</tt> return on errors, instead of
propagating the error upwards.
</p>

<table border=1 bgcolor="#FFFFE0" width=500><tr><td>
<pre>
  require "lanes"

  f= lanes.gen( function(n) error "!!!" end )
  a= f(1)

  --print( a[1] )     -- will propagate error

  v,err= a:join( nil, false )  -- no propagation
  if not v then
    error( "'a' faced error"..tostring(err) )
  end
</pre>
</table>


<!-- cancelling +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="cancelling">Cancelling</h2>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>= lane_h:cancel()</code>
</table>

<p>Cancels the substate execution, asyncronously. Cancellation will take
    effect the next time substate calls a pending <tt>receive()</tt> or <tt>send()</tt>
    or after executing max. <tt>cancelstep</tt> statements.
</p>


<!-- lindas +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="lindas">Lindas</h2>

<p>Communications between lanes is completely detached from the lane handles
themselves. By default, a lane can only provide return values once it's finished,
or throw an error. Needs to communicate during runtime are handled by <A HREF="http://en.wikipedia.org/wiki/Linda_%28coordination_language%29" TARGET="_blank">Linda objects</A>, which are 
<A HREF="#deep_userdata">deep userdata</A>. They can be provided to a lane
as startup parameters, upvalues or in some other Linda's message values.
</p><p>
Access to a Linda object means a lane can read or write to any of its data
slots. Multiple lanes can be accessing the same Linda in parallel.
</p><p>

<table border=1 bgcolor="#FFFFE0" width=500><tr><td>
<pre>
  require "lanes"

  local linda= lanes.linda()

  local function loop( max )
    for i=1,max do
        print( "sending: "..i )
        linda:send( "out", i )
    end
  end
  
  a= lanes.gen("",loop)( 10000 )

  while true do
    local val= linda:receive( 3.0, "out" )    -- timeout in seconds&nbsp;
    if val==nil then
        print( "timed out" )
        break
    end
    print( "received: "..val )
  end
</pre>
</table>

</p>
<p>Characteristics of the Lanes implementation of Lindas are:

<ul>
    <li>keys can be of number, string or boolean type
    </li>
    <li>values can be any type supported by inter-state copying (same limits
    as for function parameters, upvalues etc.)
    </li>
    <li>consuming method is <tt>:receive</tt> (not 'in')
    </li>
    <li>non-consuming method is <tt>linda[]</tt> (not 'rd')
    </li>
    <li>two producer-side methods: <tt>:send</tt> and <tt>set</tt> (not 'out')
    </li>
    <li>'eval' is not implemented, but can be easily emulated using a lane
    that outputs its results to a Linda
    </li>
    <li><tt>send</tt> allows for sending multiple values -atomically- to a
    give key
    </li>
    <li><tt>receive</tt> can wait for multiple keys at once
    </li>
    <li>individual keys' queue length can be limited, balancing speed differences
    in a producer/consumer scenario
    </li>
</ul>
</p>

<p>
<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>h= lanes.linda()</code>
    <br/><br/>
    <code>bool= h:send( [timeout_secs,] key, ... )</code>
    <br/>
    <code>[val [,key]]= h:receive( [timeout_secs,] key [, ...] )</code>
    <br/><br/>
    <code>= h:limit( key, uint [, ...] )</code>
</table>

<p>The <tt>send</tt> and <tt>receive</tt> methods use Linda keys as FIFO stacks
(first in, first out). Timeouts are given in seconds (millisecond accuracy).
If using numbers as the first Linda key, one must explicitly give <tt>nil</tt>
as the timeout parameter to avoid ambiguities.
</p><p>
By default, stack sizes are unlimited but limits can be
enforced using the <tt>limit</tt> method. This can be useful to balance execution
speeds in a producer/consumer scenario.
</p><p>
Note that any number of lanes can be reading or writing a Linda. There can be
many producers, and many consumers. It's up to you.
</p>
<p><tt>send</tt> returns <tt>true</tt> if the sending succeeded, and <tt>false</tt>
if the queue limit was met, and the queue did not empty enough during the given
timeout.
</p><p>
Equally, <tt>receive</tt> returns a value and the key that provided the value
(if multiple keys were waited upon), or <tt>nil</tt> for timeout.
Use <tt>nil</tt> or <tt>-1</tt> for no timeout (waits forever).
</p><p>
Multiple values can be sent to a given key at once, atomically (the send will
fail unless all the values fit within the queue limit). This can be useful for
multiple producer scenarios, if the protocols used are giving data in streams
of multiple units. Atomicity avoids the producers from garbling each others
messages, which could happen if the units were sent individually.
</p><p>

When receiving from multiple slots, the keys are checked in order, which can
be used for making priority queues.
</p><p>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>linda_h:set( key [, val] )</code>
    <br/>
    <code>[val]= linda_h:get( key )</code>
</table>

</p><p>
The table access methods are for accessing a slot without queuing or consuming.
They can be used for making shared tables of storage among the lanes.
</p><p>
Writing to a slot overwrites existing value, and clears any possible queued 
entries. Table access and <tt>send</tt>/<tt>receive</tt> can be used together; 
reading a slot essentially peeks the next outcoming value of a queue.
</p><p>
Note: the sole reason why <tt>set</tt> and <tt>get</tt> aren't table access
methods of Linda handle directly, is that some keys ("send", "receive", "limit", "deep")
wouldn't be usable as communication keys.
</p><p>

<p>
<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>lightuserdata= linda_h:deep()</code>
</table>

<p>There is one more method that is normally not required in applications, but
discussing it is good for general understanding of how deep userdata works.
</p><p>
Because proxy objects (<tt>linda_h</tt>) are just pointers to the real, deep
userdata, they cannot be used to identify a certain Linda from the others.
The internal timer system needs to do this, and the <tt>:deep()</tt> method
has been added for its use. It returns a light userdata pointing to the 
actual deep object, and thus can be used for seeing, which proxies actually
mean the same underlying object. You might or might not need a similar system
with your own deep userdata, but now you at least know.
</p>


<!-- timers +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="timers">Timers</h2>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td>
    <code>= lanes.timer( linda_h, key, date_tbl|first_secs [,period_secs] )</code>
</table>

<p>
Timers can be run once, or in a reoccurring fashion (<tt>period_secs > 0</tt>). 
The first occurrance can be given either as a date or as a delay in seconds. 
The <tt>date</tt> table is like what <tt>os.date("*t")</tt> returns, in the 
local time zone.
</p><p>
Once a timer expires, the <tt>key</tt> is set with the current time
(in seconds, same offset as <tt>os.time()</tt> but with millisecond accuracy). 
The key can be waited upon using the regular Linda <tt>:receive()</tt>
method.
</p><p>
A timer can be stopped simply by <tt>first_secs=0</tt> and no period.
</p><p>

<table border=1 bgcolor="#FFFFE0" width=500><tr><td>
<pre>
  require "lanes"

  local linda= lanes.linda()

  -- First timer once a second, not synchronized to wall clock
  -- (the timer does not expire at wall clock second tick)
  --
  lanes.timer( linda, "sec", 1, 1 )

  -- Timer to a future event (next even minute); wall clock synchronized
  --
  local t= os.date( "*t", os.time()+60 )    -- now + 1min
  t.sec= 0

  lanes.timer( linda, "min", t, 60 )   -- reoccur every minute
    
  while true do
    local v,key= linda:receive( 2, "sec", "min" )
    assert(v)
    
    print( "Timer "..key..": ".. os.date().." "..v )
  end  
</pre>
</table>

</p><p>
NOTE: Timer keys are set, not queued, so missing a beat is possible especially
if the timer cycle is extremely small (i.e. 0.001). The key value can be used
to know the actual time passed.
</p><p>
<table>
    <tr><td valign=top><nobr><i>Design note:</i></nobr>&nbsp;</td>
        <td>
<font size="-1">
Having the API as <tt>lanes.timer()</tt> is intensional. Another
alternative would be <tt>linda_h:timer()</tt> but timers are not traditionally
seen to be part of Lindas. Also, it would mean any lane getting a Linda handle
would be able to mess up timers on it. A third choice could
be abstracting the timers out of Linda realm altogether (<tt>timer_h= lanes.timer( date|first_secs, period_secs )</tt>)
but that would mean separate waiting functions for timers, and lindas. Even if
a linda object and key was returned, that key couldn't be waited upon simultaneously
with one's general linda events.
The current system gives maximum capabilities with minimum API, and any smoothenings
can easily be crafted in Lua at the application level.
</font>
        </td>
    </tr>
</table>
</p>


<!-- locks +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="locks">Locks, critical sections and atomic counters</h2>

<p>
Lanes does not generally require locks or critical sections to be used, at all.
If necessary, a limited queue can be used to emulate them. <tt>lanes.lua</tt>
offers some sugar to make it easy:
</p><p>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td><pre>
  lock_func= lanes.genlock( linda_h, key [,N_uint=1] )

  lock_func( M_uint )     -- acquire
    ..
  lock_func( -M_uint )    -- release
</table>
</p><p>

The generated function acquires M entries from the N available, or releases
them if the value is negative. The acquiring call will suspend the lane, if necessary.
Use <tt>M=1</tt> for a critical section lock (only one lane allowed).
</p><p>

Note: The locks generated are <u>not recursive</u>. That would need another
kind of generator, which is currently not implemented.
</p><p>

Similar sugar exists for atomic counters:
</p><p>

<table border=1 bgcolor="#E0E0FF" cellpadding=10><tr><td><pre>
  atomic_func= lanes.genatomic( linda_h, key [,initial_num=0.0] )

  num= atomic_func( [diff_num=1.0] )
</table>
</p><p>

Each time called, the generated function will change <tt>linda[key]</tt> 
atomically, without other lanes being able to interfere. The new value is
returned. You can use either <tt>diff 0.0</tt> or <tt>get</tt> to just read the current
value.
</p><p>

Note that the generated functions can be passed on to other lanes, there is
no need to re-create them per lane.
</p>


<!-- others +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="other">Other issues</h2>

<h3>Limitations on data passing</h3>

<p>Data passed between lanes (either as starting parameters, return values, upvalues or via Lindas) must conform to the following:
</p>
<p><ul>
	<li>booleans, numbers, strings, light userdata, functions and tables of those (including subtables) can be passed
	</li>
	<ul>
	   <li>duplicate references in tables are 'opened' (passed by value)
	   </li>
	   <li>cycles in tables are not allowed (will cause the state to get stuck)
	   </li>
	   <li>function upvalues are copied by value (changing an upvalue is not mirrorred in other lanes)
	   </li>
	   <li>metatables are not copied (could be)
	   </li>
    </ul>
    <li>full userdata can be passed only if it's prepared using the <tt>luaG_shared()</tt> system, which handles its lifespan management (see <A HREF="#deep_userdata">deep userdata</A>)
    </li>
    <li>coroutines cannot be passed
    </li>
</ul>
</p>


<h3>Granularity of using Lindas</h3>

<p>A single Linda object provides an infinite number of slots, so why would
you want to use several?
</p><p>There are some important reasons:

<ul>
    <li>Access control. If you don't trust certain code completely, or just
    to modularize your design, use one Linda for one usage and another one
    for the other. This keeps your code clear and readable. You can pass
    multiple Linda handles to a lane with practically no added cost.
    </li>
    
    <li>Namespace control. Linda keys have a "flat" namespace, so collisions
    are possible if you try to use the same Linda for too many separate uses.
    </li>
    
    <li>Performance. Changing any slot in a Linda causes all the pending threads
    (at least in the C level) to be awakened from their sleep. This will degrade
    performance due to unnecessary OS level context switches.
    </li>
</ul>

On the other side, you need to use a common Linda for waiting for multiple
keys. You cannot wait for keys from two separate Linda objects at the same
time.
</p>


<h3>Required of module makers</h3>

<p>
Most Lua extension modules should work unaltered with Lanes.
</p><p>
If the module simply ties C side features to Lua, everything is fine without
alterations. The <tt>luaopen_...()</tt> entry point will be called separately for each
lane, where the module is <tt>require</tt>'d.
</p><p>
If it, however, also does one-time C side initializations, these
should be covered into a one-time-only construct such as below. Note that the
module does not need to do proper OS side locking; Lanes serializes
calls to <tt>require</tt>, so no two module initializations will be overlapping
in time. You may do proper OS locking, if you want.
</p><p>

<table><tr><td width=40>
    <td bgcolor="#ffffe0">
<pre>
 int luaopen_module( lua_State *L )
 {
    static char been_here;  /* 0 by ANSI C */
    
    /* Calls to 'require' serialized by Lanes; this is safe.&nbsp;&nbsp;
    */
    if (!been_here) {
        been_here= 1;
        ... one time initializations ...
    }
    
    ... binding to Lua ...
 }
</pre>
</td></tr></table>
</p>


<h3 id="shared_userdata">Deep userdata in your own apps</h3>

<p>
The mechanism Lanes uses for sharing Linda handles between separate Lua states
can be used for custom userdata as well. Here's what you need to do.
</p>
<ol>
    <li>Provide an <i>identity function</i> for your userdata, in C. This function is
used for creation and deletion of your deep userdata (the shared resource),
and for making metatables for the state-specific proxies for accessing it.
Take a look at <tt>linda_id</tt> in <tt>lanes.c</tt>.
    </li>
    <li>Create your userdata using <tt>luaG_deep_userdata()</tt>, which is
    a Lua-callable function. Given an <tt>idfunc</tt>, it sets up the support
    structures and returns a state-specific proxy userdata for accessing your
    data. This proxy can also be copied over to other lanes.
    </li>
    <li>Accessing the deep userdata from your C code, use <tt>luaG_todeep()</tt>
    instead of the regular <tt>lua_touserdata()</tt>.
    </li>
</ol>

<p>Deep userdata management will take care of tying to <tt>__gc</tt> methods,
and doing reference counting to see how many proxies are still there for 
accessing the data. Once there are none, the data will be freed through a call
to the <tt>idfunc</tt> you provided.
</p>
<p><b>NOTE</b>: The lifespan of deep userdata may exceed that of the Lua state
that created it. The allocation of the data storage should not be tied to
the Lua state used. In other words, use <tt>malloc</tt>/<tt>free</tt> or
similar memory handling mechanism.
</p>


<h3 id="performance">Performance considerations</h3>

<p>
Lanes is about making multithreading easy, and natural in the Lua state of mind.
Expect performance not to be an issue, if your program is logically built.
Here are some things one should consider, if best performance is vital:
</p><p>
<ul>
    <li>Data passing (parameters, upvalues, Linda messages) is generally fast,
    doing two binary state-to-state copies (from source state to hidden state,
    hidden state to target state). Remember that not only the function you 
    specify but also its upvalues, their upvalues, etc. etc. will get copied.
    </li>
    <li>Lane startup is fast (1000's of lanes a second), depending on the
    number of standard libraries initialized. Initializing all standard libraries
    is about 3-4 times slower than having no standard libraries at all. If you
    throw in a lot of lanes per second, make sure you give them minimal necessary
    set of libraries.
    </li>
    <li>Waiting Lindas are woken up (and execute some hidden Lua code) each
    time <u>any</u> key in the Lindas they are waiting for are changed. This
    may give essential slow-down (not measured, just a gut feeling) if a lot
    of Linda keys are used. Using separate Linda objects for logically separate
    issues will help (which is good practise anyhow).
    </li>
    <li>Linda objects are light. The memory footprint is two OS-level signalling
    objects (<tt>HANDLE</tt> or <tt>pthread_cond_t</tt>) for each, plus one
    C pointer for the proxies per each Lua state using the Linda. Barely nothing.
    </li>
    <li>Timers are light. You can probably expect timers up to 0.001 second
    resolution to be useful, but that is very system specific. All timers are
    merged into one main timer state (see <tt>timer.lua</tt>); no OS side
    timers are required.
    </li>
</ul>
</p>


<!-- change log +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>
<h2 id="changes">Change log</h2>

<p>
Changes by version:

<pre>
Jul-2008:
  &middot; Too many changes to list (you'll need to re-read this manual)
</pre>


<!-- footnotes +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<hr/>

<p>For feedback, questions and suggestions:
<UL>
    <li><A HREF="http://luaforge.net/projects/lanes">Lanes @ LuaForge</A></li>
    <li><A HREF="mailto:akauppi@gmail.com">the author</A></li>
</UL>
</p>

<p><br/></p>

<font size="-1">
<p id="1">
    1) Extension modules get loaded only once, but they will get <i>initialized</i>
    multiple times, once per each Lua state. If the module C code uses global and/or
    static variables during its initialization, it may not work with Lanes.
</p>

<p id="2">
    2) This is similar to <tt>coroutine.status</tt>, which has: <tt>"running"</tt> /
    <tt>"suspended"</tt> / <tt>"normal"</tt> / <tt>"dead"</tt>. 
</p>
</font>

</body>
</html>
